{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary Imports\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "def read_nifti_file(filepath):\n",
    "    \"\"\"Read and load volume\"\"\"\n",
    "    # Read file\n",
    "    scan = nib.load(filepath)\n",
    "    #print(scan)\n",
    "    \n",
    "    # Get raw data\n",
    "    scan = scan.get_fdata()\n",
    "#     show_slices([scan[100, :, :],\n",
    "#              scan[:, 120, :],\n",
    "#              scan[:, :, 100]])\n",
    "#     print(np.min(scan))\n",
    "#     print(np.max(scan))\n",
    "#     print(scan.shape)\n",
    "    return scan\n",
    "\n",
    "\n",
    "def normalize(volume):\n",
    "    \"\"\"Normalize the volume\"\"\"\n",
    "#     min = -1000\n",
    "#     max = 400\n",
    "#     volume[volume < min] = min\n",
    "#     volume[volume > max] = max\n",
    "#     volume = (volume - min) / (max - min)\n",
    "    volume = volume.astype(\"float32\")\n",
    "#     print(volume)\n",
    "    return volume\n",
    "\n",
    "\n",
    "def resize_volume(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth = 64\n",
    "    desired_width = 128\n",
    "    desired_height = 128\n",
    "    # Get current depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "#     print(img)\n",
    "#     print(np.min(img))\n",
    "#     print(np.max(img))\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(img, 90, reshape=False)\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_scan(path):\n",
    "    \"\"\"Read and resize volume\"\"\"\n",
    "    # Read scan\n",
    "    volume = read_nifti_file(path)\n",
    "    # Normalize\n",
    "    volume = normalize(volume)\n",
    "    # Resize width, height and depth\n",
    "    volume = resize_volume(volume)\n",
    "    return volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TRN_0077.nii.gz']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "dt = pd.read_csv(\"Dataset\\metaData.csv\")\n",
    "type1=[]\n",
    "type2=[]\n",
    "type3=[]\n",
    "type4=[]\n",
    "type5=[]\n",
    "for i in range(len(dt.head(500))):\n",
    "    if (dt.iloc[i]['TypeOfTB']==1):\n",
    "        type1.append(dt.iloc[i]['FileName'])\n",
    "    if (dt.iloc[i]['TypeOfTB']==2):\n",
    "        type2.append(dt.iloc[i]['FileName'])\n",
    "    if (dt.iloc[i]['TypeOfTB']==3):\n",
    "        type3.append(dt.iloc[i]['FileName'])\n",
    "    if (dt.iloc[i]['TypeOfTB']==4):\n",
    "        type4.append(dt.iloc[i]['FileName'])\n",
    "    if (dt.iloc[i]['TypeOfTB']==5):\n",
    "        type5.append(dt.iloc[i]['FileName'])\n",
    "print(type3)\n",
    "print(len(type3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dataset\\\\Train\\\\TRN_0017.nii.gz', 'Dataset\\\\Train\\\\TRN_0028.nii.gz', 'Dataset\\\\Train\\\\TRN_0038.nii.gz', 'Dataset\\\\Train\\\\TRN_0050.nii.gz', 'Dataset\\\\Train\\\\TRN_0070.nii.gz', 'Dataset\\\\Train\\\\TRN_0088.nii.gz', 'Dataset\\\\Train\\\\TRN_0091.nii.gz', 'Dataset\\\\Train\\\\TRN_0092.nii.gz', 'Dataset\\\\Train\\\\TRN_0094.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "type2paths=[]\n",
    "type1paths=[]\n",
    "type3paths=[]\n",
    "type4paths=[]\n",
    "type5paths=[]\n",
    "\n",
    "\n",
    "for i in range(len(type1)):\n",
    "    temptype1=\"Dataset\\\\Train\\\\\"+type1[i]\n",
    "    type1paths.append(temptype1)\n",
    "for i in range(len(type2)):\n",
    "    temptype2=\"Dataset\\\\Train\\\\\"+type2[i]\n",
    "    type2paths.append(temptype2)\n",
    "for i in range(len(type3)):\n",
    "    temptype3=\"Dataset\\\\Train\\\\\"+type3[i]\n",
    "    type3paths.append(temptype3)\n",
    "for i in range(len(type4)):\n",
    "    temptype4=\"Dataset\\\\Train\\\\\"+type4[i]\n",
    "    type4paths.append(temptype4)\n",
    "for i in range(len(type5)):\n",
    "    temptype5=\"Dataset\\\\Train\\\\\"+type5[i]\n",
    "    type5paths.append(temptype5)\n",
    "\n",
    "print(type2paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path=\"E:\\\\TuberculosisTypeClassification\\\\test_scans\\\\\"+str(temp_all_path[i])\n",
    "type_one_scans=np.array([process_scan(path) for path in type1paths])\n",
    "  \n",
    "# #path=\"E:\\\\TuberculosisTypeClassification\\\\test_scans\\\\\"+str(temp_all_path[i])\n",
    "type_two_scans=np.array([process_scan(path) for path in type2paths])\n",
    " \n",
    "#path=\"E:\\\\TuberculosisTypeClassification\\\\test_scans\\\\\"+str(temp_all_path[i])\n",
    "type_three_scans=np.array([process_scan(path) for path in type3paths])\n",
    "\n",
    "# #path=\"E:\\\\TuberculosisTypeClassification\\\\test_scans\\\\\"+str(temp_all_path[i])\n",
    "type_four_scans=np.array([process_scan(path) for path in type4paths])\n",
    "   \n",
    "# #path=\"E:\\\\TuberculosisTypeClassification\\\\test_scans\\\\\"+str(temp_all_path[i])\n",
    "type_five_scans=np.array([process_scan(path) for path in type5paths])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "type_one = round(0.7 * len(type_one_scans))\n",
    "type_two = round(0.7 * len(type_two_scans))\n",
    "type_three = round(0.7 * len(type_three_scans))\n",
    "type_four = round(0.7 * len(type_four_scans))\n",
    "type_five = round(0.7 * len(type_five_scans))\n",
    "print(type_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train and validation are 70 and 31.\n",
      "[[[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]]\n",
      "-3.16969e-16\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "type_one_labels = np.array([0 for _ in range(len(type_one_scans))])\n",
    "type_two_labels = np.array([1 for _ in range(len(type_two_scans))])\n",
    "type_three_labels = np.array([2 for _ in range(len(type_three_scans))])\n",
    "type_four_labels = np.array([3 for _ in range(len(type_four_scans))])\n",
    "type_five_labels = np.array([4 for _ in range(len(type_five_scans))])\n",
    "\n",
    "# #Split data for training and validation into 70-30.\n",
    "x_train = np.concatenate((type_one_scans[:type_one], type_two_scans[:type_two],type_three_scans[:1], type_four_scans[:type_four],type_five_scans[:type_five]) , axis = 0)\n",
    "y_train = np.concatenate((type_one_labels[:type_one], type_two_labels[:type_two],type_three_labels[:1], type_four_labels[:type_four],type_five_labels[:type_five]), axis = 0)\n",
    "\n",
    "\n",
    "x_val =np.concatenate((type_one_scans[type_one:], type_two_scans[type_two:],type_three_scans[type_three:], type_four_scans[type_four:],type_five_scans[type_five:]) , axis = 0)\n",
    "y_val = np.concatenate((type_one_labels[type_one:], type_two_labels[type_two:],type_three_labels[type_three:], type_four_labels[type_four:],type_five_labels[type_five:]), axis = 0)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Number of samples in train and validation are %d and %d.\"\n",
    "    % (x_train.shape[0], x_val.shape[0])\n",
    ")\n",
    "#print(len(x_train))\n",
    "#print(len(y_train))\n",
    "print(x_train)\n",
    "print(np.min(x_train))\n",
    "print(np.max(x_train))\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def rotate(volume):\n",
    "    \"\"\"Rotate the volume by a few degrees\"\"\"\n",
    "\n",
    "    def scipy_rotate(volume):\n",
    "        # define some rotation angles\n",
    "        angles = [-20, -10, -5, 5, 10, 20]\n",
    "        # pick angles at random\n",
    "        angle = random.choice(angles)\n",
    "        # rotate volume\n",
    "        volume = ndimage.rotate(volume, angle, reshape=False)\n",
    "        volume[volume < 0] = 0\n",
    "        volume[volume > 1] = 1\n",
    "        return volume\n",
    "\n",
    "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
    "    return augmented_volume\n",
    "\n",
    "\n",
    "def train_preprocessing(volume, label):\n",
    "    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n",
    "    # Rotate volume\n",
    "    volume = rotate(volume)\n",
    "    volume = tf.expand_dims(volume, axis=3)\n",
    "    return volume, label\n",
    "\n",
    "\n",
    "def validation_preprocessing(volume, label):\n",
    "    \"\"\"Process validation data by only adding a channel.\"\"\"\n",
    "    volume = tf.expand_dims(volume, axis=3)\n",
    "    return volume, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function rotate at 0x0000026C694F0C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function rotate at 0x0000026C694F0C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "<PrefetchDataset shapes: (<unknown>, (None,)), types: (tf.float32, tf.int32)>\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# Define data loaders.\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "\n",
    "batch_size = 2\n",
    "# Augment the on the fly during training.\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(x_train))\n",
    "    .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")\n",
    "\n",
    "# Only rescale.\n",
    "validation_dataset = (\n",
    "    validation_loader.shuffle(len(x_val))\n",
    "    .map(validation_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")\n",
    "print(train_dataset)\n",
    "print(len(validation_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the CT scan 1 is: (512, 512, 132)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26c232e8ee0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# #for i in range (1,5):\n",
    "# data = train_dataset.take(1)\n",
    "# images, labels = list(data)[0]\n",
    "# images = images.numpy()\n",
    "# image = images[0]\n",
    "\n",
    "\n",
    "image = nib.load(\"Dataset/Train/TRN_0007.nii.gz\")\n",
    "image = image.get_fdata()\n",
    "\n",
    "print(\"Dimension of the CT scan\",1,\"is:\", image.shape)\n",
    "plt.imshow(np.squeeze(image[:, :, 63]),cmap=plt.cm.bone)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slices(num_rows, num_columns, width, height, data):\n",
    "    \"\"\"Plot a montage of 20 CT slices\"\"\"\n",
    "    data = np.rot90(np.array(data))\n",
    "    data = np.transpose(data)\n",
    "    data = np.reshape(data, (num_rows, num_columns, width, height))\n",
    "    rows_data, columns_data = data.shape[0], data.shape[1]\n",
    "    heights = [slc[0].shape[0] for slc in data]\n",
    "    widths = [slc.shape[1] for slc in data[0]]\n",
    "    fig_width = 12.0\n",
    "    fig_height = fig_width * sum(heights) / sum(widths)\n",
    "    f, axarr = plt.subplots(\n",
    "        rows_data,\n",
    "        columns_data,\n",
    "        figsize=(fig_width, fig_height),\n",
    "        gridspec_kw={\"height_ratios\": heights},\n",
    "    )\n",
    "    for i in range(rows_data):\n",
    "        for j in range(columns_data):\n",
    "            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n",
    "            axarr[i, j].axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize montage of slices.\n",
    "# 4 rows and 10 columns for 100 slices of the CT scan.\n",
    "plot_slices(4, 10, 128, 128, image[:, :, :40])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras_sequential_ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3dcnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 64, 1)] 0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 126, 126, 62, 64)  1792      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 63, 63, 31, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 63, 63, 31, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 61, 61, 29, 64)    110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 30, 30, 14, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 30, 14, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 28, 28, 12, 128)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 14, 14, 6, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 6, 128)    512       \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 12, 12, 4, 256)    884992    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 6, 6, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6, 6, 2, 256)      1024      \n",
      "_________________________________________________________________\n",
      "global_average_pooling3d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,352,897\n",
      "Trainable params: 1,351,873\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(width=128, height=128, depth=64):\n",
    "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
    "\n",
    "    inputs = keras.Input((width, height, depth, 1))\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"softmax\")(inputs)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"softmax\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"softmax\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"softmax\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(units=512, activation=\"softmax\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    outputs = layers.Dense(units=1, activation=\"softmax\")(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
    "    return model\n",
    "\n",
    "# Build model.\n",
    "model = get_model(width=128, height=128, depth=64)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3dcnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 128, 128, 64, 1)] 0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 126, 126, 62, 32)  896       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 63, 63, 31, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 63, 63, 31, 32)    128       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 63, 63, 31, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 61, 61, 29, 64)    55360     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 30, 30, 14, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 30, 14, 64)    256       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 30, 30, 14, 64)    0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 806400)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               206438656 \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 206,561,345\n",
      "Trainable params: 206,561,153\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(width=128, height=128, depth=64):\n",
    "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
    "\n",
    "    inputs = keras.Input((width, height, depth, 1))\n",
    "\n",
    "    x = layers.Conv3D(filters=32, kernel_size=3, activation=\"relu\", kernel_initializer='he_uniform')(inputs)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization(center=True, scale=True)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\", kernel_initializer='he_uniform')(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization(center=True, scale=True)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.Dense(256, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "\n",
    "    outputs = layers.Dense(units=1, activation=\"softmax\")(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
    "    return model\n",
    "\n",
    "# Build model.\n",
    "model = get_model(width=128, height=128, depth=64)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "# Define callbacks.\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"Dataset/3d_image_classification.h5\", save_best_only=True\n",
    ")\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "35/35 [==============================] - 982s 28s/step - loss: 0.0000e+00 - acc: 0.0857 - val_loss: 0.0000e+00 - val_acc: 0.0968\n",
      "Epoch 2/2\n",
      "35/35 [==============================] - 926s 26s/step - loss: 0.0000e+00 - acc: 0.0857 - val_loss: 0.0000e+00 - val_acc: 0.0968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26c001257f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model, doing validation at the end of each epoch\n",
    "epochs = 20\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, metric in enumerate([\"acc\", \"loss\"]):\n",
    "    ax[i].plot(model.history.history[metric])\n",
    "    ax[i].plot(model.history.history[\"val_\" + metric])\n",
    "    ax[i].set_title(\"Model {}\".format(metric))\n",
    "    ax[i].set_xlabel(\"epochs\")\n",
    "    ax[i].set_ylabel(metric)\n",
    "    ax[i].legend([\"train\", \"val\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "This model is 100.00 percent confident that CT scan is 0\n",
      "[1.]\n",
      "This model is 100.00 percent confident that CT scan is 0\n",
      "[1.]\n",
      "This model is 100.00 percent confident that CT scan is 0\n",
      "[1.]\n",
      "This model is 100.00 percent confident that CT scan is 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-237b14192a9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m#print(y_val[i])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load best weights.\n",
    "\n",
    "model.load_weights(\"Dataset/3d_image_classification.h5\")\n",
    "\n",
    "for i in range(len(x_val)):\n",
    "    \n",
    "    prediction = model.predict(np.expand_dims(x_val[i], axis=0))\n",
    "    #print(y_val[i])\n",
    "    scores = prediction\n",
    "    class_names=str(y_val[i])\n",
    "\n",
    "\n",
    "    for score, name in zip(scores, class_names):\n",
    "        print(score)\n",
    "        print(\n",
    "            \"This model is %.2f percent confident that CT scan is %s\"\n",
    "            % ((100 * score), name)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"3d_image_classification.h5\")\n",
    "\n",
    "prediction = model.predict(np.expand_dims(x_val[2], axis=0))[0]\n",
    "scores = [1 - prediction[0], prediction[0]]\n",
    "\n",
    "class_names = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "for score, name in zip(scores, class_names):\n",
    "    print(score)\n",
    "    print(\n",
    "        \"This model is %.2f percent confident that CT scan is %s\"\n",
    "        % ((100 * score), name)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
